{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiCiu6FnfVbH6pnnCB2jf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpratap17/DeepLearningLab/blob/main/DL_Lab_Exp_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THEORETICAL BACKGROUND:\n",
        "Tensors are multi-dimensional arrays that generalize vectors and matrices to\n",
        "higher dimensions. They are the fundamental data structure in deep learning:\n",
        "- 0D tensor (scalar): A single number\n",
        "- 1D tensor (vector): An array of numbers\n",
        "- 2D tensor (matrix): A table of numbers\n",
        "- 3D+ tensors: Higher-dimensional arrays\n",
        "\n",
        "PyTorch tensors support GPU acceleration and automatic differentiation,\n",
        "making them ideal for deep learning.\n",
        "NumPy arrays are CPU-based and widely\n",
        "used for scientific computing."
      ],
      "metadata": {
        "id": "YvZOU_dquPEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary modules\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "GnsjbtiHHEhq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Tensors can be created in multiple dimensions to represent different types of data:\n",
        "- 1D: Time series, audio signals, feature vectors\n",
        "- 2D: Images (grayscale), tabular data, weight matrices\n",
        "- 3D: RGB images, video frames, text embeddings (batch, sequence, features)"
      ],
      "metadata": {
        "id": "GyOKmWbHvCQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1. CREATING 1D, 2D, AND 3D TENSORS\")\n",
        "print(\"\\n--- PyTorch ---\")\n",
        "pt_1d = torch.tensor([1, 2, 3, 4, 5])\n",
        "pt_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "pt_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "print(f\"1D Tensor: {pt_1d}, Shape: {pt_1d.shape}\")\n",
        "print(f\"2D Tensor:\\n{pt_2d}\\nShape: {pt_2d.shape}\")\n",
        "print(f\"3D Tensor:\\n{pt_3d}\\nShape: {pt_3d.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUPX6AQ9ourg",
        "outputId": "1aec59f8-526e-4622-d153-79049df50458"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. CREATING 1D, 2D, AND 3D TENSORS\n",
            "\n",
            "--- PyTorch ---\n",
            "1D Tensor: tensor([1, 2, 3, 4, 5]), Shape: torch.Size([5])\n",
            "2D Tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Shape: torch.Size([2, 3])\n",
            "3D Tensor:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "Shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- NumPy ---\")\n",
        "np_1d = np.array([1, 2, 3, 4, 5])\n",
        "np_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "np_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "print(f\"1D Array: {np_1d}, Shape: {np_1d.shape}\")\n",
        "print(f\"2D Array:\\n{np_2d}\\nShape: {np_2d.shape}\")\n",
        "print(f\"3D Array:\\n{np_3d}\\nShape: {np_3d.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmdD-XwLpB_5",
        "outputId": "9afe7ee8-819f-40db-bf20-2e523e14266b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- NumPy ---\n",
            "1D Array: [1 2 3 4 5], Shape: (5,)\n",
            "2D Array:\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Shape: (2, 3)\n",
            "3D Array:\n",
            "[[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[5 6]\n",
            "  [7 8]]]\n",
            "Shape: (2, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Tensor operations form the building blocks of neural network computations:\n",
        "- Element-wise operations: Applied independently to each element\n",
        "- Dot product: Scalar result from two vectors\n",
        "- Matrix multiplication: Core operation in neural network layers\n",
        "\n",
        "MATHEMATICAL FORMULAS:\n",
        "\n",
        "Element-wise addition: C[i] = A[i] + B[i]\n",
        "\n",
        "Dot product: result = Σ(A[i] * B[i])\n",
        "\n",
        "Matrix multiplication: C[i,j] = Σ(A[i,k] * B[k,j]"
      ],
      "metadata": {
        "id": "mP5NJoq4vncz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"2. BASIC OPERATIONS\")\n",
        "\n",
        "# Create sample tensors\n",
        "a_pt = torch.tensor([10, 20, 30])\n",
        "b_pt = torch.tensor([1, 2, 3])\n",
        "a_np = np.array([10, 20, 30])\n",
        "b_np = np.array([1, 2, 3])\n",
        "\n",
        "print(\"\\n--- Element-wise Operations (PyTorch) ---\")\n",
        "print(f\"a = {a_pt}, b = {b_pt}\")\n",
        "print(f\"Addition: {a_pt + b_pt}\")\n",
        "print(f\"Subtraction: {a_pt - b_pt}\")\n",
        "print(f\"Multiplication: {a_pt * b_pt}\")\n",
        "print(f\"Division: {a_pt / b_pt}\")\n",
        "\n",
        "print(\"\\n--- Element-wise Operations (NumPy) ---\")\n",
        "print(f\"a = {a_np}, b = {b_np}\")\n",
        "print(f\"Addition: {a_np + b_np}\")\n",
        "print(f\"Subtraction: {a_np - b_np}\")\n",
        "print(f\"Multiplication: {a_np * b_np}\")\n",
        "print(f\"Division: {a_np / b_np}\")\n",
        "\n",
        "print(\"\\n--- Dot Product ---\")\n",
        "print(f\"PyTorch dot product: {torch.dot(a_pt, b_pt)}\")\n",
        "print(f\"NumPy dot product: {np.dot(a_np, b_np)}\")\n",
        "\n",
        "print(\"\\n--- Matrix Multiplication ---\")\n",
        "mat1_pt = torch.tensor([[1, 2], [3, 4]])\n",
        "mat2_pt = torch.tensor([[5, 6], [7, 8]])\n",
        "mat1_np = np.array([[1, 2], [3, 4]])\n",
        "mat2_np = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "print(f\"PyTorch matmul:\\n{torch.matmul(mat1_pt, mat2_pt)}\")\n",
        "print(f\"PyTorch @ operator:\\n{mat1_pt @ mat2_pt}\")\n",
        "print(f\"NumPy matmul:\\n{np.matmul(mat1_np, mat2_np)}\")\n",
        "print(f\"NumPy @ operator:\\n{mat1_np @ mat2_np}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ir-CeRp6RQ",
        "outputId": "19708b42-0378-4fbc-b812-0429fa7f83bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. BASIC OPERATIONS\n",
            "\n",
            "--- Element-wise Operations (PyTorch) ---\n",
            "a = tensor([10, 20, 30]), b = tensor([1, 2, 3])\n",
            "Addition: tensor([11, 22, 33])\n",
            "Subtraction: tensor([ 9, 18, 27])\n",
            "Multiplication: tensor([10, 40, 90])\n",
            "Division: tensor([10., 10., 10.])\n",
            "\n",
            "--- Element-wise Operations (NumPy) ---\n",
            "a = [10 20 30], b = [1 2 3]\n",
            "Addition: [11 22 33]\n",
            "Subtraction: [ 9 18 27]\n",
            "Multiplication: [10 40 90]\n",
            "Division: [10. 10. 10.]\n",
            "\n",
            "--- Dot Product ---\n",
            "PyTorch dot product: 140\n",
            "NumPy dot product: 140\n",
            "\n",
            "--- Matrix Multiplication ---\n",
            "PyTorch matmul:\n",
            "tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "PyTorch @ operator:\n",
            "tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "NumPy matmul:\n",
            "[[19 22]\n",
            " [43 50]]\n",
            "NumPy @ operator:\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Indexing and slicing allow efficient access to tensor subsets without copying data:\n",
        "- Basic indexing: Access specific elements or rows/columns\n",
        "- Slicing: Extract contiguous regions using start:stop:step syntax\n",
        "- Boolean masking: Filter elements based on conditions\n",
        "- Advanced indexing: Use lists/tensors to select specific indices\n",
        "\n",
        "SYNTAX:\n",
        "-------\n",
        "tensor[row, col]        # Single element\n",
        "\n",
        "tensor[start:end]       # Slice from start to end-1\n",
        "\n",
        "tensor[::step]          # Every step-th element\n",
        "\n",
        "tensor[condition]       # Boolean mask"
      ],
      "metadata": {
        "id": "IA0f77k8wb7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"3. INDEXING AND SLICING\")\n",
        "\n",
        "tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "array = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "\n",
        "print(f\"\\nOriginal:\\n{tensor}\")\n",
        "print(f\"\\n--- Basic Indexing ---\")\n",
        "print(f\"Element at [1, 2]: {tensor[1, 2]}\")\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "\n",
        "print(f\"\\n--- Slicing ---\")\n",
        "print(f\"First 2 rows, first 3 cols:\\n{tensor[:2, :3]}\")\n",
        "print(f\"Every other element in row 1: {tensor[1, ::2]}\")\n",
        "\n",
        "print(f\"\\n--- Boolean Masking (PyTorch) ---\")\n",
        "mask = tensor > 6\n",
        "print(f\"Mask (elements > 6):\\n{mask}\")\n",
        "print(f\"Elements > 6: {tensor[mask]}\")\n",
        "\n",
        "print(f\"\\n--- Boolean Masking (NumPy) ---\")\n",
        "mask_np = array > 6\n",
        "print(f\"Elements > 6: {array[mask_np]}\")\n",
        "\n",
        "print(f\"\\n--- Advanced Indexing ---\")\n",
        "indices = torch.tensor([0, 2])\n",
        "print(f\"Rows 0 and 2:\\n{tensor[indices]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1DOC1xQq8Ez",
        "outputId": "a3e85428-e794-4a14-dfb0-598e98462073"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. INDEXING AND SLICING\n",
            "\n",
            "Original:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "--- Basic Indexing ---\n",
            "Element at [1, 2]: 7\n",
            "First row: tensor([1, 2, 3, 4])\n",
            "First column: tensor([1, 5, 9])\n",
            "\n",
            "--- Slicing ---\n",
            "First 2 rows, first 3 cols:\n",
            "tensor([[1, 2, 3],\n",
            "        [5, 6, 7]])\n",
            "Every other element in row 1: tensor([5, 7])\n",
            "\n",
            "--- Boolean Masking (PyTorch) ---\n",
            "Mask (elements > 6):\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False,  True,  True],\n",
            "        [ True,  True,  True,  True]])\n",
            "Elements > 6: tensor([ 7,  8,  9, 10, 11, 12])\n",
            "\n",
            "--- Boolean Masking (NumPy) ---\n",
            "Elements > 6: [ 7  8  9 10 11 12]\n",
            "\n",
            "--- Advanced Indexing ---\n",
            "Rows 0 and 2:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 9, 10, 11, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Shape manipulation is crucial for preparing data for neural networks:\n",
        "- reshape(): Changes tensor shape, may copy data\n",
        "- view(): Changes shape, shares memory (requires contiguous data)\n",
        "- squeeze(): Removes dimensions of size 1\n",
        "- unsqueeze(): Adds dimensions of size 1\n",
        "\n",
        "KEY DIFFERENCES:\n",
        "\n",
        "- view() is faster but requires contiguous memory\n",
        "- reshape() always works but may copy data\n",
        "- Use -1 in reshape/view to infer dimension automatically"
      ],
      "metadata": {
        "id": "mbujujJhw0ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"4. RESHAPE, VIEW, SQUEEZE, UNSQUEEZE\")\n",
        "\n",
        "x = torch.arange(12)\n",
        "print(f\"\\nOriginal tensor: {x}, Shape: {x.shape}\")\n",
        "\n",
        "print(\"\\n--- .view() in PyTorch ---\")\n",
        "x_view = x.view(3, 4)\n",
        "print(f\"view(3, 4):\\n{x_view}\")\n",
        "print(f\"view(-1, 2) (infer dimension):\\n{x.view(-1, 2)}\")\n",
        "\n",
        "print(\"\\n--- .reshape() in PyTorch ---\")\n",
        "x_reshape = x.reshape(4, 3)\n",
        "print(f\"reshape(4, 3):\\n{x_reshape}\")\n",
        "\n",
        "print(\"\\n--- .reshape() in NumPy ---\")\n",
        "x_np = np.arange(12)\n",
        "print(f\"reshape(3, 4):\\n{x_np.reshape(3, 4)}\")\n",
        "\n",
        "print(\"\\n--- .unsqueeze() - Add dimension ---\")\n",
        "y = torch.tensor([1, 2, 3])\n",
        "print(f\"Original: {y}, Shape: {y.shape}\")\n",
        "print(f\"unsqueeze(0): {y.unsqueeze(0)}, Shape: {y.unsqueeze(0).shape}\")\n",
        "print(f\"unsqueeze(1): {y.unsqueeze(1)}, Shape: {y.unsqueeze(1).shape}\")\n",
        "\n",
        "print(\"\\n--- .squeeze() - Remove dimension ---\")\n",
        "z = torch.tensor([[[1, 2, 3]]])\n",
        "print(f\"Original shape: {z.shape}\")\n",
        "print(f\"After squeeze(): {z.squeeze()}, Shape: {z.squeeze().shape}\")\n",
        "\n",
        "print(\"\\n--- NumPy expand_dims and squeeze ---\")\n",
        "y_np = np.array([1, 2, 3])\n",
        "print(f\"expand_dims(axis=0): {np.expand_dims(y_np, axis=0)}, Shape: {np.expand_dims(y_np, axis=0).shape}\")\n",
        "z_np = np.array([[[1, 2, 3]]])\n",
        "print(f\"squeeze(): {np.squeeze(z_np)}, Shape: {np.squeeze(z_np).shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV-NZJC0rcdV",
        "outputId": "428b46e7-af89-4063-b482-2a2f38380056"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. RESHAPE, VIEW, SQUEEZE, UNSQUEEZE\n",
            "\n",
            "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), Shape: torch.Size([12])\n",
            "\n",
            "--- .view() in PyTorch ---\n",
            "view(3, 4):\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "view(-1, 2) (infer dimension):\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11]])\n",
            "\n",
            "--- .reshape() in PyTorch ---\n",
            "reshape(4, 3):\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "--- .reshape() in NumPy ---\n",
            "reshape(3, 4):\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]]\n",
            "\n",
            "--- .unsqueeze() - Add dimension ---\n",
            "Original: tensor([1, 2, 3]), Shape: torch.Size([3])\n",
            "unsqueeze(0): tensor([[1, 2, 3]]), Shape: torch.Size([1, 3])\n",
            "unsqueeze(1): tensor([[1],\n",
            "        [2],\n",
            "        [3]]), Shape: torch.Size([3, 1])\n",
            "\n",
            "--- .squeeze() - Remove dimension ---\n",
            "Original shape: torch.Size([1, 1, 3])\n",
            "After squeeze(): tensor([1, 2, 3]), Shape: torch.Size([3])\n",
            "\n",
            "--- NumPy expand_dims and squeeze ---\n",
            "expand_dims(axis=0): [[1 2 3]], Shape: (1, 3)\n",
            "squeeze(): [1 2 3], Shape: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Broadcasting allows operations between tensors of different shapes without\n",
        "explicit replication. The smaller tensor is virtually \"stretched\" to match\n",
        "the larger tensor's shape.\n",
        "\n",
        "BROADCASTING RULES:\n",
        "\n",
        "1. Compare dimensions from right to left\n",
        "2. Dimensions are compatible if:\n",
        "   - They are equal, OR\n",
        "   - One of them is 1\n",
        "3. Missing dimensions are treated as 1"
      ],
      "metadata": {
        "id": "jmbxrk8dxldy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"5. BROADCASTING\")\n",
        "\n",
        "print(\"\\n--- Example 1: Scalar with Vector ---\")\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = 10\n",
        "print(f\"{a} + {b} = {a + b}\")\n",
        "\n",
        "print(\"\\n--- Example 2: Vector with Matrix ---\")\n",
        "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "vector = torch.tensor([10, 20, 30])\n",
        "print(f\"Matrix:\\n{matrix}\")\n",
        "print(f\"Vector: {vector}\")\n",
        "print(f\"Result:\\n{matrix + vector}\")\n",
        "\n",
        "print(\"\\n--- Example 3: Different Dimensions ---\")\n",
        "x = torch.ones(3, 1)\n",
        "y = torch.ones(1, 4)\n",
        "print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
        "print(f\"Result shape: {(x + y).shape}\")\n",
        "print(f\"Result:\\n{x + y}\")\n",
        "\n",
        "print(\"\\n--- NumPy Broadcasting ---\")\n",
        "a_np = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "b_np = np.array([10, 20, 30])\n",
        "print(f\"Result:\\n{a_np + b_np}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9xfqiHHrqwb",
        "outputId": "16b1f0c7-ca47-48b1-ceda-7b19558c2c2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5. BROADCASTING\n",
            "\n",
            "--- Example 1: Scalar with Vector ---\n",
            "tensor([1, 2, 3]) + 10 = tensor([11, 12, 13])\n",
            "\n",
            "--- Example 2: Vector with Matrix ---\n",
            "Matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Vector: tensor([10, 20, 30])\n",
            "Result:\n",
            "tensor([[11, 22, 33],\n",
            "        [14, 25, 36]])\n",
            "\n",
            "--- Example 3: Different Dimensions ---\n",
            "x shape: torch.Size([3, 1]), y shape: torch.Size([1, 4])\n",
            "Result shape: torch.Size([3, 4])\n",
            "Result:\n",
            "tensor([[2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.]])\n",
            "\n",
            "--- NumPy Broadcasting ---\n",
            "Result:\n",
            "[[11 22 33]\n",
            " [14 25 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCEPT:\n",
        "\n",
        "Operations can either create new tensors or modify existing ones:\n",
        "- Out-of-place: Creates new tensor, original unchanged (safer)\n",
        "- In-place: Modifies original tensor directly (memory efficient)\n",
        "\n",
        "PYTORCH CONVENTION:\n",
        "\n",
        "Operations ending with underscore (_) are in-place: add_, mul_, etc.\n",
        "Operations without underscore create new tensors: add, mul, etc.\n",
        "\n",
        "\n",
        "Out-of-place: Uses more memory but safer for gradients\n",
        "In-place: Saves memory but can break gradient computation"
      ],
      "metadata": {
        "id": "xFgE9uY5x02o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"6. IN-PLACE vs OUT-OF-PLACE OPERATIONS\")\n",
        "\n",
        "print(\"\\n--- Out-of-place (creates new tensor) ---\")\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(f\"Original: {x}\")\n",
        "y = x + 10\n",
        "print(f\"After y = x + 10:\")\n",
        "print(f\"  x = {x} (unchanged)\")\n",
        "print(f\"  y = {y} (new tensor)\")\n",
        "\n",
        "print(\"\\n--- In-place (modifies original) ---\")\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(f\"Original: {x}\")\n",
        "x.add_(10)  # Note the underscore\n",
        "print(f\"After x.add_(10): {x} (modified)\")\n",
        "\n",
        "print(\"\\n--- Common In-place Operations in PyTorch ---\")\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Original: {x}\")\n",
        "x.mul_(2)  # x *= 2\n",
        "print(f\"After mul_(2): {x}\")\n",
        "x.sub_(1)  # x -= 1\n",
        "print(f\"After sub_(1): {x}\")\n",
        "x.div_(2)  # x /= 2\n",
        "print(f\"After div_(2): {x}\")\n",
        "\n",
        "print(\"\\n--- NumPy In-place Operations ---\")\n",
        "x_np = np.array([1, 2, 3])\n",
        "print(f\"Original: {x_np}\")\n",
        "x_np += 10\n",
        "print(f\"After += 10: {x_np}\")\n",
        "\n",
        "print(\"\\n--- Warning: view() and in-place operations ---\")\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "y = x.view(4)\n",
        "print(f\"x:\\n{x}\")\n",
        "print(f\"y (view): {y}\")\n",
        "y[0] = 99\n",
        "print(f\"After y[0] = 99:\")\n",
        "print(f\"  x:\\n{x} (also changed! view shares memory)\")\n",
        "print(f\"  y: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r0dmc56sGf4",
        "outputId": "2f45be7f-6722-4540-95ea-abb50f95a7f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6. IN-PLACE vs OUT-OF-PLACE OPERATIONS\n",
            "\n",
            "--- Out-of-place (creates new tensor) ---\n",
            "Original: tensor([1, 2, 3])\n",
            "After y = x + 10:\n",
            "  x = tensor([1, 2, 3]) (unchanged)\n",
            "  y = tensor([11, 12, 13]) (new tensor)\n",
            "\n",
            "--- In-place (modifies original) ---\n",
            "Original: tensor([1, 2, 3])\n",
            "After x.add_(10): tensor([11, 12, 13]) (modified)\n",
            "\n",
            "--- Common In-place Operations in PyTorch ---\n",
            "Original: tensor([1., 2., 3.])\n",
            "After mul_(2): tensor([2., 4., 6.])\n",
            "After sub_(1): tensor([1., 3., 5.])\n",
            "After div_(2): tensor([0.5000, 1.5000, 2.5000])\n",
            "\n",
            "--- NumPy In-place Operations ---\n",
            "Original: [1 2 3]\n",
            "After += 10: [11 12 13]\n",
            "\n",
            "--- Warning: view() and in-place operations ---\n",
            "x:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "y (view): tensor([1, 2, 3, 4])\n",
            "After y[0] = 99:\n",
            "  x:\n",
            "tensor([[99,  2],\n",
            "        [ 3,  4]]) (also changed! view shares memory)\n",
            "  y: tensor([99,  2,  3,  4])\n"
          ]
        }
      ]
    }
  ]
}