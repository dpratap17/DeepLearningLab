{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnIHKhofptteXJFTFJdUvW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpratap17/DeepLearningLab/blob/main/DL_Lab_Exp5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sra-d9PqD6sJ",
        "outputId": "7e295ac3-4c59-4f8a-e090-0bf85736c989"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  O my Luve's like a red, red rose\\nThat’s newly...\n",
              "1  The rose is red,\\nThe violet's blue,\\nSugar is...\n",
              "2  How do I love thee? Let me count the ways.\\nI ...\n",
              "3  Had I the heavens' embroidered cloths,\\nEnwrou...\n",
              "4  I.\\n    Enough! we're tired, my heart and I.\\n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca2173c5-20bc-4230-a3d3-5a02d92ce2a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca2173c5-20bc-4230-a3d3-5a02d92ce2a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca2173c5-20bc-4230-a3d3-5a02d92ce2a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca2173c5-20bc-4230-a3d3-5a02d92ce2a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Three little birds in a row\\nSat musing.\\nA man passed near that place.\\nThen did the little birds nudge each other.\\n\\nThey said, \\\"He thinks he can sing.\\\"\\nThey threw back their heads to laugh.\\nWith quaint countenances\\nThey regarded him.\\nThey were very curious,\\nThose three little birds in a row.\",\n          \"  I think I could turn and live with animals, they are so placid and\\n      self-contain'd,\\n  I stand and look at them long and long.\\n\\n  They do not sweat and whine about their condition,\\n  They do not lie awake in the dark and weep for their sins,\\n  They do not make me sick discussing their duty to God,\\n  Not one is dissatisfied, not one is demented with the mania of\\n      owning things,\\n  Not one kneels to another, nor to his kind that lived thousands of\\n      years ago,\\n  Not one is respectable or unhappy over the whole earth.\\n\\n  So they show their relations to me and I accept them,\\n  They bring me tokens of myself, they evince them plainly in their\\n      possession.\\n\\n  I wonder where they get those tokens,\\n  Did I pass that way huge times ago and negligently drop them?\\n\\n  Myself moving forward then and now and forever,\\n  Gathering and showing more always and with velocity,\\n  Infinite and omnigenous, and the like of these among them,\\n  Not too exclusive toward the reachers of my remembrancers,\\n  Picking out here one that I love, and now go with him on brotherly terms.\\n\\n  A gigantic beauty of a stallion, fresh and responsive to my caresses,\\n  Head high in the forehead, wide between the ears,\\n  Limbs glossy and supple, tail dusting the ground,\\n  Eyes full of sparkling wickedness, ears finely cut, flexibly moving.\\n\\n  His nostrils dilate as my heels embrace him,\\n  His well-built limbs tremble with pleasure as we race around and return.\\n\\n  I but use you a minute, then I resign you, stallion,\\n  Why do I need your paces when I myself out-gallop them?\\n  Even as I stand or sit passing faster than you.\",\n          \"  And as to you Death, and you bitter hug of mortality, it is idle to\\n      try to alarm me.\\n\\n  To his work without flinching the accoucheur comes,\\n  I see the elder-hand pressing receiving supporting,\\n  I recline by the sills of the exquisite flexible doors,\\n  And mark the outlet, and mark the relief and escape.\\n\\n  And as to you Corpse I think you are good manure, but that does not\\n      offend me,\\n  I smell the white roses sweet-scented and growing,\\n  I reach to the leafy lips, I reach to the polish'd breasts of melons.\\n\\n  And as to you Life I reckon you are the leavings of many deaths,\\n  (No doubt I have died myself ten thousand times before.)\\n\\n  I hear you whispering there O stars of heaven,\\n  O suns\\u2014O grass of graves\\u2014O perpetual transfers and promotions,\\n  If you do not say any thing how can I say any thing?\\n\\n  Of the turbid pool that lies in the autumn forest,\\n  Of the moon that descends the steeps of the soughing twilight,\\n  Toss, sparkles of day and dusk\\u2014toss on the black stems that decay\\n      in the muck,\\n  Toss to the moaning gibberish of the dry limbs.\\n\\n  I ascend from the moon, I ascend from the night,\\n  I perceive that the ghastly glimmer is noonday sunbeams reflected,\\n  And debouch to the steady and central from the offspring great or small.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/poems-100.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CR4zjQLtFH-B",
        "outputId": "eb9e56f0-c6bd-408a-c3c1-1c255e4fd02c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(df['text'].astype(str)).lower()\n"
      ],
      "metadata": {
        "id": "BSBRfhe-FPko"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = re.sub(r'\\n', ' ', text)\n",
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "text = re.sub(r'\\s+', ' ', text).strip()\n"
      ],
      "metadata": {
        "id": "CCvwK00OFXdl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])\n",
        "print(\"Total words:\", len(text.split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4hDFoKdCFgJZ",
        "outputId": "6d552fb9-7b4e-45bd-b554-236dea46ae17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o my luves like a red red rose thats newly sprung in june o my luves like the melodie thats sweetly playd in tune as fair art thou my bonnie lass so deep in luve am i and i will luve thee still my dear till a the seas gang dry till a the seas gang dry my dear and the rocks melt wi the sun i will luve thee still my dear while the sands o life shall run and fare thee well my only luve and fare thee well a while and i will come again my luve tho it were ten thousand mile the rose is red the violets\n",
            "Total words: 24676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "metadata": {
        "id": "Uxi_N10UFjS1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "vocab = sorted(set(words))\n",
        "\n",
        "word_to_ix = {w:i for i,w in enumerate(vocab)}\n",
        "ix_to_word = {i:w for w,i in word_to_ix.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BH-3yuhXFwrw",
        "outputId": "a1d0e744-cbac-4275-d9bc-bd52f68439b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 5439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(idx, size):\n",
        "    vec = np.zeros(size)\n",
        "    vec[idx] = 1\n",
        "    return vec\n"
      ],
      "metadata": {
        "id": "ErPjrhqTF_yh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Numpy:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h_prev) + self.bh)\n",
        "        y = np.dot(self.Why, h) + self.by\n",
        "        return h, y\n"
      ],
      "metadata": {
        "id": "gXMFRSFOGC-u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 50\n",
        "rnn = RNN_Numpy(vocab_size, hidden_size, vocab_size)\n",
        "\n",
        "h_prev = np.zeros((hidden_size, 1))\n",
        "x = one_hot(word_to_ix[words[0]], vocab_size).reshape(-1,1)\n",
        "\n",
        "h, y = rnn.forward(x, h_prev)\n",
        "print(\"Forward pass successful\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KLzNmd_uGGRU",
        "outputId": "8f234889-d41d-4d2a-f1e2-ad307093ea55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward pass successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "\n",
        "data = []\n",
        "targets = []\n",
        "\n",
        "for i in range(len(words) - sequence_length):\n",
        "    data.append(words[i:i+sequence_length])\n",
        "    targets.append(words[i+sequence_length])\n"
      ],
      "metadata": {
        "id": "_4wYYK8IGLFo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot_sequence(seq):\n",
        "    return torch.tensor(\n",
        "        [one_hot(word_to_ix[w], vocab_size) for w in seq],\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "X = torch.stack([to_one_hot_sequence(seq) for seq in data])\n",
        "y = torch.tensor([word_to_ix[t] for t in targets])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vPdp8RKNGVKY",
        "outputId": "01640717-8001-4204-9518-904ee8379f3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1498319719.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  return torch.tensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "XJ_4YE_JGX8B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "batch_size = 64\n",
        "dataset = TensorDataset(X_idx, y_idx)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "epochs = 40\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model_emb(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wsmnGRsaG30_",
        "outputId": "ea7edf5c-9cbb-40d2-dfe1-fe59923ff0e9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 6.7226\n",
            "Epoch 2, Loss: 6.0710\n",
            "Epoch 3, Loss: 5.6453\n",
            "Epoch 4, Loss: 5.2211\n",
            "Epoch 5, Loss: 4.7994\n",
            "Epoch 6, Loss: 4.3844\n",
            "Epoch 7, Loss: 3.9842\n",
            "Epoch 8, Loss: 3.6096\n",
            "Epoch 9, Loss: 3.2683\n",
            "Epoch 10, Loss: 2.9622\n",
            "Epoch 11, Loss: 2.6861\n",
            "Epoch 12, Loss: 2.4409\n",
            "Epoch 13, Loss: 2.2188\n",
            "Epoch 14, Loss: 2.0203\n",
            "Epoch 15, Loss: 1.8364\n",
            "Epoch 16, Loss: 1.6696\n",
            "Epoch 17, Loss: 1.5174\n",
            "Epoch 18, Loss: 1.3753\n",
            "Epoch 19, Loss: 1.2449\n",
            "Epoch 20, Loss: 1.1280\n",
            "Epoch 21, Loss: 1.0171\n",
            "Epoch 22, Loss: 0.9152\n",
            "Epoch 23, Loss: 0.8259\n",
            "Epoch 24, Loss: 0.7403\n",
            "Epoch 25, Loss: 0.6631\n",
            "Epoch 26, Loss: 0.5928\n",
            "Epoch 27, Loss: 0.5286\n",
            "Epoch 28, Loss: 0.4700\n",
            "Epoch 29, Loss: 0.4175\n",
            "Epoch 30, Loss: 0.3689\n",
            "Epoch 31, Loss: 0.3264\n",
            "Epoch 32, Loss: 0.2875\n",
            "Epoch 33, Loss: 0.2526\n",
            "Epoch 34, Loss: 0.2222\n",
            "Epoch 35, Loss: 0.1934\n",
            "Epoch 36, Loss: 0.1693\n",
            "Epoch 37, Loss: 0.1488\n",
            "Epoch 38, Loss: 0.1291\n",
            "Epoch 39, Loss: 0.1123\n",
            "Epoch 40, Loss: 0.0974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.min(y_idx), torch.max(y_idx))\n",
        "print(len(set(y_idx.tolist())))\n",
        "print(vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rU9SAnQmOBjR",
        "outputId": "5f73152a-cff3-457e-fe41-bd58c7dc0a91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0) tensor(5438)\n",
            "5439\n",
            "5439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fake = torch.randint(0, vocab_size, y_idx.shape)\n",
        "out = model_emb(X_idx[:64])\n",
        "loss = criterion(out, y_fake[:64])\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rqNBGUV9OJ7u",
        "outputId": "af49f5d5-8b73-4c72-be6c-ad40841beb31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21.807804107666016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for xb, yb in loader:\n",
        "    optimizer.zero_grad()\n",
        "    out = model_emb(xb)\n",
        "    loss = criterion(out, yb)\n",
        "    print(\"Batch loss:\", loss.item())\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1B2QTnSPWka",
        "outputId": "22367d78-e094-40f8-bbb8-15a8d5191d82"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch loss: 0.05334652587771416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model_emb(X_idx[:64])\n",
        "print(out.max().item(), out.min().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPxSKhp4PfI8",
        "outputId": "0589fded-71bc-43a9-aba9-46d7f88684c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.46104621887207 -17.693201065063477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_onehot(start_words, length=20):\n",
        "    model_oh.eval()\n",
        "    words_generated = start_words[:]\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words_generated[-sequence_length:]\n",
        "        x = to_one_hot_sequence(seq).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            out = model_oh(x)\n",
        "        next_word = ix_to_word[out.argmax().item()]\n",
        "        words_generated.append(next_word)\n",
        "\n",
        "    return \" \".join(words_generated)\n",
        "\n",
        "print(generate_text_onehot(words[:5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "odxtKPGUG7pZ",
        "outputId": "2b178d57-f7f4-4426-881d-290b50bdd822"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o my luves like a the the the the the the the the the the the the the the the the the the the the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_idx = torch.tensor([[word_to_ix[w] for w in seq] for seq in data])\n",
        "y_idx = torch.tensor([word_to_ix[t] for t in targets])\n"
      ],
      "metadata": {
        "id": "56eUN6rbHb6P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "7sMN7XD9Hneb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_emb = RNN_Embedding(vocab_size, 50, 128)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_emb.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_emb(X_idx)\n",
        "    loss = criterion(outputs, y_idx)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FTASxLofHsce",
        "outputId": "f18d56ad-a6e6-4677-b617-26bd21ec0781"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 8.6277\n",
            "Epoch 2, Loss: 8.5974\n",
            "Epoch 3, Loss: 8.5667\n",
            "Epoch 4, Loss: 8.5346\n",
            "Epoch 5, Loss: 8.5003\n",
            "Epoch 6, Loss: 8.4625\n",
            "Epoch 7, Loss: 8.4197\n",
            "Epoch 8, Loss: 8.3700\n",
            "Epoch 9, Loss: 8.3113\n",
            "Epoch 10, Loss: 8.2410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_embedding(start_words, length=20):\n",
        "    model_emb.eval()\n",
        "    words_generated = start_words[:]\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words_generated[-sequence_length:]\n",
        "        x = torch.tensor([[word_to_ix[w] for w in seq]])\n",
        "        with torch.no_grad():\n",
        "            out = model_emb(x)\n",
        "        next_word = ix_to_word[out.argmax().item()]\n",
        "        words_generated.append(next_word)\n",
        "\n",
        "    return \" \".join(words_generated)\n",
        "\n",
        "print(generate_text_embedding(words[:5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g2VWnaUaHvbs",
        "outputId": "602afcad-c4a9-439d-ccf9-3a619f69fa2b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o my luves like a ring precious snowflakes ruts are gone of the just of the just of the just of the just of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-LHItVSH9h3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}